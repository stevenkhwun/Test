---
title: 'Chapter 1: Exploratory Data Analysis'
output:
  html_document:
    number_sections: yes
  pdf_document: default
date: '2023-03-04'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Estimates of Location

The dataset `state.csv` is used to demonstrate the calculation of the various estimates of location.

```{r}
# Import the dataset
csv <- "https://raw.githubusercontent.com/stevenkhwun/Online-resources/refs/heads/main/Data/Practical-Statistics/state.csv"
state <- read.csv(csv)
```

```{r}
# First few observations
head(state)
# Summary statistics
summary(state)
```

The boxplot of the variable `Population` is displayed below:

```{r, echo=FALSE}
boxplot(state[['Population']])
```



## Percentile (quantile)
The value such that *P* percent of the data lies below.




# Estimates of variability

## Deviations (errors, residuals)
The difference between the observed values and the estimate of location.

## Variance (mean-squared-error)
The sum of squared deviations from the mean divided by $n-1$ where $n$ is the number of data values.

```{r}
# Variance
var(state[['Population']])
```

The `var()` function in base *R* calculates the sample variance by the following formula:


$$\text{Variance}=s^2=\frac{\sum_{i=1}^{n}{(x_i-\overline{x})^2}}{n-1}$$
**Degree of Freedom, and $n$ or $n-1$**

We have $n–1$ in the denominator in the variance formula, instead of n, leading into the concept of *degrees of freedom*. It is based on the premise that you want to make estimates about a population, based on a sample.

If you use the intuitive denominator of $n$ in the variance formula, you will underestimate the true value of the variance and the standard deviation in the population. This is referred to as a *biased estimate*. However, if you divide by $n–1$ instead of $n$, the variance becomes an *unbiased estimate*.

To fully explain why using $n$ leads to a *biased estimate* involves the notion of *degrees of freedom*, which takes into account the number of constraints in computing an estimate. In this case, there are $n–1$ degrees of freedom since there is one constraint: the standard deviation depends on calculating the sample mean.

## Standard deviation
The square root of the variance.

```{r}
# Standard deviation
sd(state[['Population']])
```

Similarly, the `sd()` function in base *R* calculates the sample standard deviation.

$$\text{Standard deviation}=s=\sqrt{\text{Variance}}$$

We can write function to calculate the population mean, variance and standard deviation. The following is an example:

```{r}
# Functions return population mean, variance and standard deviation
mvsdp <- function(x)
{
  # x is the vector of values
  n   <- length(x)       # recover size
  mux <- sum(x)/n        # mean
  ex2 <- sum(x^2)/n      # E(X^2)
  s2x <- ex2 - mux^2     # alternative variance
  sdx <- sqrt(s2x)       # SD
  return(c(mux,s2x,sdx)) # return the triple
}
```


```{r}
# Calculate the population triple for the population
mvsdp(state[['Population']])
```

We can get the sample estimates by minor modification of the code:

```{r}
# Functions return sample mean, variance and standard deviation
mvsds <- function(x)
{
  # x is the vector of values
  n    <- length(x)        # recover size
  mux  <- sum(x)/n         # mean
  ex2  <- sum(x^2)/n       # E(X^2)
  s2x  <- ex2 - mux^2      # alternative variance
  s2xs <- s2x*(n/(n-1))    # sample variance
  sdxs<-  sqrt(s2xs)       # SD
  return(c(mux,s2xs,sdxs)) # return the triple
}
```

```{r}
# Calculate the sample triple for the population
mvsds(state[['Population']])
```

These results match the result by the built-in functions in base *R*.

## Mean absolute deviation (l1-norm, Manhattan norm)
The mean of the absolute values of the deviations from the mean.

The mean absolute deviation is computed with the formula:

$$\text{Mean absolute deviation} = \frac{\sum_{i=1}^{n}|{x_i-\overline{x}}|}{n}$$
where $\overline{x}$ is the sample mean.

## Median absolute deviation from the median (MAD)
The median of the absolute values of the deviations from the median.

Neither the *variance*, the *standard deviation*, nor the *mean absolute deviation* is robust to outliers and extreme values. The *variance* and *standard deviation* are especially sensitive to outliers since they are based on the squared deviations. A robust estimate of variability is the *median absolute deviation from the median* or **MAD**:

$$\text{Median absolute deviation}=\text{Median}(|x_1-m|,|x_2-m|,...,|x_N-m|)$$
where $m$ is the median. Like the median, the MAD is not influenced by extreme values.

```{r}
# Mean absolute deviation from the median (MAD)
mad(state[['Population']])
```


## Order statistics (ranks)
Metrics based on the data values sorted from smallest to biggest.


## Range
The difference between the largest and the smallest value in a data set.

The minimum and maximum values themselves are useful to know and are helpful in identifying outliers, but the range is extremely sensitive to outliers and not very useful as a general measure of dispersion in the data.


## Percentile (quantile)
To avoid the sensitivity to outliers, we can look at the range of the data after dropping values from each end. Formally, these types of estimates are based on differences between *percentiles*.

The value such that $P$ percent of the values take on this value or less and $(100-P)$ percent take on this value or more.

## Interquantile range (IQR)
A common measurement of variability is the difference between the 25th percentile and the 75th percentile, called the *interquartile range* (or IQR).

```{r}
# Interquartile range (IQR)
IQR(state[['Population']])
```

# Exploring the data distribution

## Percentiles
Percentiles are valuable for summarizing the entire distribution. It is common to report the quartiles (25th, 50th, and 75th percentiles) and the deciles (the 10th, 20th, …, 90th percentiles). Percentiles are especially valuable for summarizing the tails (the outer range) of the distribution. Popular culture has coined the term one-percenters to refer to the people in the top 99th percentile of wealth.

The following *R* code produce the percentiles of the murder rate by state.
```{r}
# Percentiles of the murder rate by state
quantile(state[['Murder.Rate']], p=c(.05, .25, .5, .75, .95))
```
The median is 4 murders per 100,000 people, although there is quite a bit of variability: the 5th percentile is only 1.6 and the 95th percentile is 6.51.

## Boxplot (box and whiskers plot)
*Boxplots* are based on percentiles and give a quick way to visualize the distribution of data.

```{r}
# Boxplot of the population by state
boxplot(state[['Population']]/1000000, ylab='Population (million)')
```

The top and bottom of the box are the 75th and 25th percentiles, respectively. The median is shown by the horizontal line in the box. The dashed lines, referred to as *whiskers*, extend from the top and bottom of the box to indicate the range for the bulk of the data. By default, the *R* function extends the *whiskers* to the furthest point beyond the box, except that it will not go beyond 1.5 times the IQR. Any data outside of the *whiskers* is plotted as single points or circles (often considered outliers).


## Frequency table
A tally of the count of numeric data values that fall into a set of intervals (bins).


```{r}
# Frequency table of the population by state
breaks <- seq(from=min(state[['Population']]),
              to=max(state[['Population']]), length=11)
pop_freq <- cut(state[['Population']], breaks=breaks,
                right=TRUE, include.lowest=TRUE)
table(pop_freq)
```


## Histogram
A plot of the frequency table with the bins on the x-axis and the count (or proportion) on the y-axis. While visually similar, bar charts should not be confused with histograms.

```{r}
# Histogram
hist(state[['Population']], breaks=breaks, xlab='Population', main='Histogram of Population')
```

## Density plot
A smoothed version of the histogram, often based on a *kernel density estimate*. A density plot shows the distribution of data values as a continuous line.

In *R*, you can compute a density estimate using the density function:

```{r}
# Density estimate superposed on a histogram
hist(state[['Murder.Rate']], freq=FALSE, main='Density of state muder rates',
     ylab='Density', xlab='Murder Rate (per 100,000)')
lines(density(state[['Murder.Rate']]))
```

